also has master slave architecture
master listens to the clients and spins up containers on workers
these managed containers, managed by the master instance is called a pod
we can have multiple containers in a single pod
whats the point of pods?
containers in the same pod can share the file system
![[Pasted image 20241111234712.png]]

api server is the daemon that listens for kube commands
etcd is a distributed in memory cache
	multiple masters can share data in the etcd, responsible for implementing logs with in the cluster to ensure there are no conflicts
Scheduler
	responsible for distributing containers across multiple nodes
Controller
	controllers are the mind behind the orchestration, they monitor the pods/nodes and respond to the failure

- **API Server Validation & Storage**
    - When an API server receives a request to create a pod, it **validates** the request and stores the **pod specification** in **etcd** as the desired state.
- **Controller Manager Reconciliation**
    - The **kube-controller-manager** continuously watches **etcd** via the **API server** for changes.
    - When it detects a new pod specification, it checks the **current state** against the **desired state** and ensures appropriate controllers (e.g., ReplicaSet, Deployment) act accordingly.
- **Scheduler Assigns a Node**
    - The **kube-scheduler** watches **etcd** via the **API server** for pods that **do not have a node assigned**.
    - It selects a suitable node based on scheduling constraints (e.g., resources, affinity/anti-affinity, taints, and tolerations).
    - Once a decision is made, it **updates the pod object in etcd via the API server**, assigning it to a specific node.
- **Kubelet Receives Pod Assignment**
    - The **kubelet does not watch etcd directly**. Instead, it **polls the API server** or **receives updates via a watch mechanism**.
    - When the kubelet sees a new pod assigned to its node, it:
        - Pulls the necessary container images.
        - Creates and starts the pod using the **container runtime** (e.g., containerd, CRI-O, or Docker).
        - Continuously monitors and reports the podâ€™s status back to the API server.

the controller manager manages
- deployment controller
- jobs controller
- replica set controller
	- helps bring failed pods back up, helps maintain replicas of pods
	- helps balance the load across multiple nodes, can create pods on multiple nods


Kubernetes features a container runtime to run the containers (containerd)
![[Pasted image 20241112000301.png]]

the container runtime is the allocated os resources where the containers run
kubelet is another daemon(agent) that keeps on running and spins up containers in the container runtime
kube-proxy is the reverse proxy manager, to redirect http requests to the correct containers

Containerd comes with a CLI tool called ctr
>ctr images pull docker.io/library/redis:alpine
>ctr run docker.io/library/redis:alpine redis

very limited better to use the nerdctl tool, it is almost like docker 
provides access to features not yet implemented in docker
>nerdctl run --name redis -p 80:80 -d redis:alpine

these two tools are containerd specific
crictl is a cli tool which is runtime agnostic as long as the runtime is CRI compatible
used primarily only for inspection and debugging
# KIND 

to create kubernetes cluster on your local machine
> curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.18.0/kind-linux-amd64
> chmod +x ./kind
> sudo mv ./kind /usr/local/bin/kind
> kind--version
> kind create cluster --name local

with this we will be able to create a master node on our machine, basically a container named local-control-plane
we can delete this cluster with
> kind delete cluster -n local

# multi node setup in kind
we can create a multi node setup with yml
```yml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
  - role: control-plane
  - role: worker
  - role: worker
```

> kind create cluster --config clusters.yml --name local

now if we check the list of running containers we will see 3 and the control plane will have an api address and a port where we can hit the kubernetes api
why? because the master node has an api server inside it

![[Pasted image 20241122021522.png]]

how to tell the master node to create a pod on a worker node? using the kubernetes API
but it requires authentication
To authenticate its stored in .kube/config
> cat ~/.kube/config

when we use kubectl it tries to find the content of ~/.kube/config
reads the auth creds from there and uses the kubernetes api to send commands to the master node's api server

when we create an aks cluster they will give us a config file that we need to put in this directory ~/.    kube of the machine we want to send kubectl commands to the master node

> kubectl cluster-info
> kubectl get nodes