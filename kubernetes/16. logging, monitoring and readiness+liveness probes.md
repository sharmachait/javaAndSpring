### pod lifecycle
when a pod is created its in Pending state
it remains in a pending state until scheduler figures out where to place it

once scheduled it goes into ContainerCreating status, this is where the images are pulled etc

it then goes into Running state

it then has two possibilities, Completed or Terminated

when this information is not sufficient we use conditions which compliment the states

conditions are an array of true or false values, which indicate the state of the pod

> PodScheduled    =    TRUE | FALSE
> Initialized    =    TRUE | FALSE
> ContainersReady    =    TRUE | FALSE
> Ready    =    TRUE | FALSE

can be seen in the Conditions section when we do
>kubectl describe pod pod-name

why do we want to know the state and the conditions?
because the state may be running but the containers may all not be ready

and in that case if we try to reach it via service we will face an error

and even if the container is ready the application code may take some time to be up

we need to tie the Ready state with the actual state of the application code 

can be achieved via Readiness Probes
which can be 
1. api calls for backend applications
2. socket connections in case of databases
3. simple exec commands in the containers

### Readiness Probes

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: simple-webapp
  labels:
    name: simple-webapp
spec:
  containers:
  - name: simple-webapp
    image: simple-webapp
    readinessProbe:
      initialDelaySeconds: 10
      periodSeconds: 5
      failureThreshold: 8
      httpGet:
        path: /api/ready
        port: 8080
    ports:
    - containerPort: 8080
```

with this spec kubernetes wont immediately set the container state to be Ready
it instead runs the readiness probe, and only sets state to be ready when the application responds positively, with a 2xx series code

use the **initialDelaySeconds** property if we know our application takes some time to start up

to specify how often to probe use the **periodSeconds** property, it will do the probe test after that many seconds again and again

by default the probe will stop after 3 attempts, we can increase the number of attempts with **failureThreshold**

and until the state is set to ready, a service wont forward the traffic to the pod, in case we have a service

for databases we can do a TCP test by connecting to the port of the database

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: simple-webapp
  labels:
    name: simple-webapp
spec:
  containers:
  - name: simple-webapp
    image: simple-webapp
    readinessProbe:
      tcpSocket:
        port: 3306
    ports:
    - containerPort: 8080
```

and to run commands use the exec probe

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: simple-webapp
  labels:
    name: simple-webapp
spec:
  containers:
  - name: simple-webapp
    image: simple-webapp
    readinessProbe:
      exec:
        command:
          - cat
          - /app
    ports:
    - containerPort: 8080
```

### merits of readiness probes

if we have a deployment with 3 replicas and a service is directing traffic to 2 pods as of now, when the deployment brings up another pod, without the readiness probe, the service will start directing traffic to the third pod immediately, even if the application code is not up and running

If a readiness probe fails:

1. The pod's Ready condition will be set to False
2. The pod will be removed from service endpoint lists (meaning it won't receive traffic from Services)
3. The pod continues running - its state doesn't change

If a readiness probe succeeds:

1. The pod's Ready condition will be set to True
2. The pod will be added to service endpoint lists
3. The pod continues running normally

### Liveness Probes

we start a deployment with 3, and we have a service directing traffic to them. 
for some reason the code crashed on one of the pod, but the service is still directing traffic to it
we want the service to stop directing traffic to it
can be achieved via liveness probes
if the liveness probe test fails the container is destroyed and a new one is created

probes can again be of the same three types
everything remains the same, just instead of readiness we specify liveness property

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: simple-webapp
  labels:
    name: simple-webapp
spec:
  containers:
  - name: simple-webapp
    image: simple-webapp
    livenessProbe:
      initialDelaySeconds: 10
      periodSeconds: 5
      failureThreshold: 8
      httpGet:
        path: /api/ready
        port: 8080
    ports:
    - containerPort: 8080
```