## Service (exposing pods)

since pods are ephemeral they die and come back up, and with new IP addresses, each pod has a unique IP address
its hard to keep track of them
that where services come in

a service is what exposes our pods to internet

we can see the IP address of our pods with
> kubectl get pods -owide

thse are private IPs and can be used by the pods to talk to each other
but not through the internet

![[Pasted image 20241127000045.png]]

an abstraction that logically define the pods and the set of policies by which to access them. 
allows us to expose application in pods as network services

Services use labels to select the pods that are being targeted

there are three types of services
1. **ClusterIP** - exposes the service on an internal IP of the cluster, this is the default service type. makes the pod accessible only within the cluster
2. **NodePort** - exposes the service on each Node's IP at a static port. the NodePort routes to a ClusterIP which is automatically created. 
  we can contact the underlying Pod from outside the cluster by requesting `<NodeIp>:<NodePort>`
  3. **LoadBalancer** - Exposes the service externally using a cloud providers load balancer. a loadbalancer routes to the NodePorts and ClusterIPs the load balancer routes to are created automatically


## commands to deploy service

creating a ClusterIp
>kubectl  expose pod redis --port=6379 --name redis-service --dry-run=client -o yaml

this command will automatically use the pod's labels as selectors
or we can also do this

>kubectl create service clusterip redis --tcp=6379:6379 --dry-run=client -o yaml

this does not use pod's label as selector instead it assumes **app=redis** as label

its not possible to pass in selectors as an option

##### creating a node port is way  more challenging

> kubectl expose pod nginx --port=80 --name nginx-service --type=NodePort --dry-run=client -o yaml

but this doesnt allow us to specify and change the nodeport, we would have to generate the manifest change the ndoe port to our liking and then re apply, because by default it create a port randomly between 30000-32767

or we can also do
>kubectl create service nodeport nginx --tcp=80:80 --node-port=30080 --dry-run=client -o yaml

but like before it doesnt accept a selector so we would haev to generate manifest change and apply

### manifest for a service

```yml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30007  # This port can be any valid port within the NodePort range
  type: NodePort
```

this will make the pod with selector app: nginx accessible to the outside world on the IP address of the node it is on

but we dont know the IP of the node, we want to be able to use the IP address of the host machine which we do know
to be able to do that we want to map the nodePort of the node to a port of the host, try to keep them same

```yml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 30007
    hostPort: 30007
- role: worker
- role: worker
```

if we start our cluster with this yaml it will map the port 30007 of our localhost to the port 30007 of the nodes
and then that port can be used in NodePort services

but this is only for KIND, this can be done via GUI on azure

now if we have three pods with label app: nginx, the NodePort service will automatically load balance over them

![[Pasted image 20241127005515.png]]
this is only doable in development with KIND
not recommended for production scenarios
this external port mapping on the kind node can be done on any of the nodes not necessarily required to be on the master node

in production we can simply deploy a loadbalancer that will provision an external IP address for us but on some cloud proovider
```yml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service-lb
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80         # The port on the LoadBalancer
      targetPort: 80    # The port on the pods
  type: LoadBalancer   # This type triggers the provisioning of an external IP
```
![[Pasted image 20241127020221.png]]
### drawbacks of services

if we have a microservice architecture it will require us to deploy a load balancer for each of the microservice
i will also require multiple certificates for each of the domain names mapped in the load balancers
each load balancer will require us to configure rate limiting in them individually
## Ingress

if we want to use ingresses we have to install the ingress controller
popular options are nginx-ingress-controller and haproxy-ingress-controller

ingress is an api object to manage external access to services in a cluster via http.
load balacing
ssl termination
name based virtual hosting
![[Pasted image 20241128081003.png]]
![[Pasted image 20241128102505.png]]
1. create deployment
2. create cluster ip service
3. create ingress - will create the load balancer for us

### installing ingress controller

nginx-ingress-controller.yml created by helm

helm helps manage these charts
>helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
>helm repo update
>helm install nginx-ingress ingress-nginx/ingress-nginx --namespace ingress-nginx --create-namespace

this will create tje pods for the ingress in the ingress-nginx namespace
and a loadbalancer service and s cluster ip

we still need to define the rules to be able to use the ingress but this creates the infrastructure

![[Pasted image 20241129004654.png]]
to be able to do this we need to use an ingress manifest
nginx.yml
```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: default
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:alpine
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
  namespace: default
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: ClusterIP
```
apache.yml
```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: apache-deployment
  namespace: default
spec:
  replicas: 2
  selector:
    matchLabels:
      app: apache
  template:
    metadata:
      labels:
        app: apache
    spec:
      containers:
      - name: my-apache-site
        image: httpd:2.4
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: apache-service
  namespace: default
spec:
  selector:
    app: apache
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: ClusterIP
```
ingress.yml
```yml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web-apps-ingress
  namespace: default
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
  - host: your-domain.com
    http:
      paths:
      - path: /nginx
        pathType: Prefix
        backend:
          service:
            name: nginx-service
            port:
              number: 80
      - path: /apache
        pathType: Prefix
        backend:
          service:
            name: apache-service
            port:
              number: 80
```

the annotation
```yml
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
```

defines that any request that comes maybe like "/apache" should be redirected to "/" when it reaches the pod serving this request, that is the landing page of the service
maybe becuase our code doesnt work on /apache and /nginx