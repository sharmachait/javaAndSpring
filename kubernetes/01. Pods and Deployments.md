# kubectl
## we can get all the nodes of the cluster with

> kubectl get nodes

if we want to see the api calls that are going out to the master node we can suffix any command with --v=8
> kubectl get nodes --v=8
![[Pasted image 20241122023122.png]]

## create a pod 

>`kubectl run <podName> --image=<imageName> --port=80`
>`kubectl run nginx --image=nginx --port=80`

what this creates looks something like this
![[Pasted image 20241122025603.png]]
its still not enough to expose it over the internet
to discover a pod is a whole different thing

this is one way to create a pod
## manifest
other way is create a manifest file
```yml
apiVersion: v1
kind: Pod
metadata:
	name: nginx
	labels: 
		app: nginx
spec: 
	containers:
		- name: nginx
		  image: nginx
		  ports:
			  - containerPorts: 80
```
>`kubectl apply -f manifest.yml`

we can extract an existing pod's definition to manifest file with the following command
>`kubectl get pods <podname> -o yaml > deployment.yml`

we can make changes to this file and apply it back to edit an existing pod 

we can have multiple; pod configs in the same file and when we apply the file both would be applied
![[Pasted image 20241122182137.png]]
or we can create deployments
## get pods

>`kubectl get pods`
>`kubectl get pods -w`

this keeps watching we dont have to run the get pods command again and again
## logs of a pod

>`kubectl logs nginx`

## describe a pod

>`kubectl dscribe pod nginx`
![[Pasted image 20241122030435.png]]
## delete pod

>`kubectl delete pod <name>`

if i have multiple container running on the same pod they have the same ip address, because they share same network namespace, this enables to communicate via local host
If two containers in the same Pod try to bind to theÂ **same port**, a conflict will occur because both containers share the same network namespace. The second container will fail to start due to the port collision.
### multicontainer pods
dont deploy the same container again in the same pod for scalability
deploy the same image on another pod
containers that are in a supporting role to the main process should be deployed along with the main container on the same Pod like MongoDB and the Mongo GUI application
those two containers will be able to communicate with each other using local host as they will part of the same network space and they can share the same FS as well
## deployment
higher level abstraction that manages a set of Pods and provides declarative updates to them
provides scaling rolling updates and rollback capabilities

 calculates the difference that needs to be applied by examining the current state and the end state that we want
 ![[Pasted image 20241122222107.png]]
a deployment technically creates a replicaset
replicaset is what mananges pods
## deployment example with 3 pods
deployment.yml
```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

1. apiVersion
2. kind
3. metadata
4. spec
these four top level fields are required and must be specified

the matchlabels in the selector are what help identify the pods from this deployment
the template is then applied to the pods with the given labels

if after this i create e a pod with the label nginx the Deployment will delete it because it was told the final state should have 3 Pods with the label of nginx

the following assigns labels to the pods while 
```yaml
template:
	metadata: 
		labels:
			app: nginx
```

the selector is used to identify the pods belonging to this deployment

if we try to create another pod with the same label
the under lying replicaset will delete it, because it already has three pods being managed by it
>kubectl run nginx-pod --image=nginx --labels="app=nginx"

we can apply any of the yml manifests with, it doesnt have to be a pod manifest to apply it
> `kubectl apply -f <name>`

we can get our deployments with 
>kubectl get deployment

will show something like
![[Pasted image 20241126013050.png]]
now even if we delete a pod with kubectl delete the deployment (replicaset) will up another pod to match the deployment

technically a deployment is just a contract, it under the hood creates a replicaset and the replicaset makes sure that there are always n number of pods as mentioned in the contract

then why do we need deployments?
it provides features like rolling updates
it maintains a history of rollouts which can be inspected with

> kubectl rollout history deployment/nginx-deployment

we can update deployments configuration even after they are deployed and then roll them back

>kubectl set image deployment/nginx-deployment nginx=nginx:1.17

the `nginx=` in the above command comes from the container name that is defined in the manifest.yml
```yml
spec:
  containers:
  - name: nginx
	image: nginx:latest
```

we can undo the changes to the image the above command would have made to the deployment with
>kubectl rollout undo deployment/nginx-deployment

we can see the currently used image with 
>kubectl describe deployment nginx-deployment

we can get replicasets with 
>kubectl get replicaset

think of replica sets as state machines
it has the desired state and the current state and calculates the diff in an infinte loop to get to the desried state
the control-place has a controller for replicaset
the label selectors are used by the replicaset to identify and manage pods
![[Pasted image 20241126014658.png]]
clean up the clusters with 
>kubectl delete deployment nginx-deployment

it will delete the deployment the replicaset and the pods for us

## series of events when we apply a manifest

1. **Command Execution**:
- You execute the command on a machine with `kubectl` installed and configured to interact with your Kubernetes cluster.
2. **API Request**:
- `kubectl` sends a request to the Kubernetes API server to create a Deployment resource with the specified parameters.
3. **API Server Processing**:
- The API server receives the request, validates it, and then processes it. If the request is valid, the API server updates the desired state of the cluster stored in etcd. The desired state now includes the new Deployment resource.
4. **Deployment Controller Monitoring**:
- The Deployment controller, which is part of the `kube-controller-manager`, continuously watches the API server for changes to Deployments. It detects the new Deployment you created.
5. **ReplicaSet Creation**:
- The Deployment controller creates a ReplicaSet based on the Deployment's specification. The ReplicaSet is responsible for maintaining a stable set of replica Pods running at any given time.
6. **Pod Creation**:
- The ReplicaSet controller (another part of the `kube-controller-manager`) ensures that the desired number of Pods (in this case, 3) are created and running. It sends requests to the API server to create these Pods.
7. **Scheduler Assignment**:
- The Kubernetes scheduler watches for new Pods that are in the "Pending" state. It assigns these Pods to suitable nodes in the cluster based on available resources and scheduling policies.
8. **Node and Kubelet**:
- The kubelet on the selected nodes receives the Pod specifications from the API server. It then pulls the necessary container images (nginx in this case) and starts the containers.
## replica set manifest

```yml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-replicaset
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

## rolling updates via deployments

lets say we first applied the below manifest
```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```
>kubectl apply -f manifest.yml

it will start three pods for us

if we change the image name to something incorrect like a typo with `nignx:latest`
and re apply the deployment manifest with the same name

kubernetes will first try to start one pod with this image, if it successful it will kill one of the old pods and try to create a new one again
K8s will do that in a loop untill the final state changes according to the new deployment, but incase it is not able to start a new pod with that image it wont delete the old pod
if we try to get all pods we will be able to see the status of one of the pods to be errored out
![[Pasted image 20241126132320.png]]

we can check more logs of the crashed deployment with
>kubectl logs -f nginx-deployment-54bd4799cb-964b7

in which case we can roll back our changes with
>kubectl rollout undo deployment/nginx-deployment

these are called rolling updates

## passing environment variables via the manifest file

```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pg-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: pg
  template:
    metadata:
      labels:
        app: pg
    spec:
      containers:
      - name: pg
        image: postgres:latest
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_PASSWORD
          value: "yourpassword"
```
we can simply apply this and this will supply the env variables
we can also set environment variables when creating pods with kubectl run command
>kubectl run example-pod --image=nginx --env="var1=val1" --env="var2=val2"
### Namespaces

>kubectl get pods --all-namespaces
>kubectl get namespaces
>`kubectl get pods --namespace <name>`

we can create pods in a namespace by adding it to the metadata section of the manifest
```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: server
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```
when we make changes to a manifest and reapply it updates the old pods if they have the same name and are in the same namespace
but if we change the name or the namespace in the manifest kubernetes will create new pods for us as these two used to identify the deployment

we can set the context of the namesapce for the rest of my commands
if i set the context to backend then we can simply do kubectl get pods and tht will run for that namespace
>kubectl config set-context --current --namespace=server
>kubectl get pods 